{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bus241a Spring 2022: Problem set 7 starter file\n",
    "\n",
    "Due Friday, March 18th at midnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load helpers\n",
    "# Will try to just load what I need on this\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cross-validation helpers\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate linear data experiments\n",
    "def genLinData(N,M,noise):\n",
    "    # y = x_1 + x_2 .. x_usedM + eps\n",
    "    usedM = 25\n",
    "    sigNoise = np.sqrt(1./usedM)\n",
    "    rescale = 0.001\n",
    "    X = np.random.normal(size=(N,M),loc=0,scale=sigNoise)\n",
    "    eps = np.random.normal(size=N,loc=0,scale=noise)\n",
    "    # build linear model\n",
    "    y = np.sum(X[:,0:usedM],axis=1)+eps\n",
    "    XMScale = X.copy()\n",
    "    # rescale half of all predictors (every other one)\n",
    "    XMScale[:,0::2] = rescale*X[:,0::2]\n",
    "    # return both regular predictors, and rescaled ones (for model confusion)\n",
    "    return X,XMScale, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is this experiment doing?\n",
    "\n",
    "Look a little at the genLinData function.  What is is trying to do?  What is the difference between X and XMscale feature variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XMScale is scaled so the variance of explained part is same order as noise variance (if noise = 1)\n",
    "X is the regular predictors without scalling and SMScale is rescaled predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Theoretical R-squared\n",
    "\n",
    "Generate a large sample of data using\n",
    "\n",
    "X,Xs, y = genLinData(10000,100,1.0)\n",
    "\n",
    "Report the usual mean train and test scores using a randomized cross validation with n_splits = 250, and test_size = 0.25.  Use just the (X,y) pair, and ignore Xs in this part.\n",
    "\n",
    "This part is just to get you a feel for what the theoretical best R-squared would be which is the same as the R-squared for an infitely large sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Xs, y = genLinData(10000,100,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5115995589653072\n",
      "0.49674805546202644\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = LinearRegression()\n",
    "# Set up randomized cross validation\n",
    "shuffle = ShuffleSplit(n_splits=250, test_size=.25)\n",
    "CVInfo = cross_validate(lr, X, y, cv=shuffle,return_train_score=True)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear regression\n",
    "\n",
    "Now shift to a more difficult small sample using,\n",
    "\n",
    "X, Xs, y = genLinData(500,100,1.0)\n",
    "\n",
    "Use n_splits = 250, and test_size = 0.25 in a typical randomized cross validation for a linear regression model.  Report the mean score in the training and test sample.\n",
    "\n",
    "To make sure you get exactly the same train/test splits, set the random_state parameter in your call to ShuffleSplit to 10.\n",
    "\n",
    "Do this for for (X,y), and then do it for (Xs,y).  How do your results compare?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Xs, y = genLinData(500,100,1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5977483458187949\n",
      "0.2284480786075488\n"
     ]
    }
   ],
   "source": [
    "# For X,y\n",
    "\n",
    "lr = LinearRegression()\n",
    "# Set up randomized cross validation\n",
    "shuffle = ShuffleSplit(n_splits=250, test_size=.25,random_state=10)\n",
    "CVInfo = cross_validate(lr, X, y, cv=shuffle,return_train_score=True)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5977483458187949\n",
      "0.22844807860754532\n"
     ]
    }
   ],
   "source": [
    "# For Xs,y\n",
    "lr = LinearRegression()\n",
    "# Set up randomized cross validation\n",
    "shuffle = ShuffleSplit(n_splits=250, test_size=.25,random_state=10)\n",
    "CVInfo = cross_validate(lr, Xs, y, cv=shuffle,return_train_score=True)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models have over fitting problem and generate almost identical low test and train sscores.Scaling has an impact on the magnitude of coefficients but it does not have any impact on the model predictions. Hence, in terms of getting the predictions, the 2 linear regression models are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ridge regression\n",
    "\n",
    "Repeat exactly what you did in the last part, except now use a ridge regression with alpha = 10.\n",
    "How do your results compare in the two cases? What does this tell you about the impact of data scales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27047452986044596\n",
      "0.13283651217667927\n"
     ]
    }
   ],
   "source": [
    "# For Xs,y\n",
    "rd =  Ridge(alpha=10)\n",
    "# Set up randomized cross validation\n",
    "shuffle = ShuffleSplit(n_splits=250, test_size=.25,random_state=10)\n",
    "CVInfo = cross_validate(rd, Xs, y, cv=shuffle,return_train_score=True)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4899742553338249\n",
      "0.2806657759781399\n"
     ]
    }
   ],
   "source": [
    "# For X,y\n",
    "rd =  Ridge(alpha=10)\n",
    "# Set up randomized cross validation\n",
    "shuffle = ShuffleSplit(n_splits=250, test_size=.25,random_state=10)\n",
    "CVInfo = cross_validate(rd, X, y, cv=shuffle,return_train_score=True)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the sacaled date, Xs, has minor over-fitting problem compared to the non-scaled data, X.\n",
    "If the values of the features are closer to each other there are chances for the algorithm to get trained well and faster instead of the data set where the data points or features values have high differences with each other will take more time to understand the data and the accuracy will be lower. Ridge regression impose the penalty on the size of the coefficients. When the scales are different for the variables, they will have different contributions to the penalized terms since the penalized term is the sum of squares of all the coefficients. Hence, having the data on the same scale is important for Ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. KNN\n",
    "\n",
    "Repeat exactly what you did in the past two sections for KNN regression (n_neighbors = 25).  Again, compare results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1579462811470064\n",
      "0.08122936528739348\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=25)\n",
    "nmc=250\n",
    "# Again, scikit-learn tools\n",
    "shuffle = ShuffleSplit(n_splits=nmc, test_size=.25)\n",
    "CVInfo = cross_validate(knn, X, y, cv=shuffle,return_train_score=True)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13656514698583624\n",
      "0.05823248119353205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X, Xs, y = genLinData(500,100,1.0)\n",
    "shuffle = ShuffleSplit(n_splits=250, test_size=.25)\n",
    "knn = KNeighborsRegressor(n_neighbors=25)\n",
    "\n",
    "\n",
    "CVInfo = cross_validate(knn, Xs, y, cv=shuffle,return_train_score=True)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Ridge regression, the mean train and test score for (Xs, y) pair is less than that of (X, y) pair. This might be because since KNN uses feature values to calculate the distance. The features with larger scale will have more weight and dominate the distance calculation.the values of the feature dimensions that have smaller range  may become uninformative and the algorithm would essentially rely on the single dimension whose range of values are substantially larger.So, normalization is important for knn model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Ridge with a single StandardScaler() on the full sample\n",
    "\n",
    "Try running the standard scaler across the full sample for the feature set Xs.  fit() and then transform().\n",
    "\n",
    "Run Ridge on this new rescaled data with the alpha_fit = 10. hyperparameter.\n",
    "\n",
    "Perform the same monte-carlo cross validation for this model as before. Print the mean score in the training and testing data.  Are your results getting closer to linear regression?\n",
    "\n",
    "Print out the vector of standard deviations for your rescaled feature set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6381210118727696\n",
      "0.31744643155338137\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(Xs)\n",
    "scaler_tf = scaler.transform(Xs)\n",
    "ridge = Ridge(alpha=10)\n",
    "shuffle = ShuffleSplit(n_splits=250, test_size=.25)\n",
    "CVInfo = cross_validate(ridge,scaler_tf,y, cv=shuffle,return_train_score=True)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the results are getting closer to linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Pipeline\n",
    "\n",
    "Now set this up with a formal pipeline built from StandardScaler() and Ridge(alpha=10).  Build \n",
    "the pipeline model, and run it through the same monte-carlo cross validation you have been doing.  Again do\n",
    "this with the (Xs,y) pair.\n",
    "\n",
    "Did your results change from the last run?  Is this model doing anything differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6425118042431737\n",
      "0.347622380884018\n"
     ]
    }
   ],
   "source": [
    "#method 1\n",
    "from sklearn.pipeline import make_pipeline\n",
    "shuffle = ShuffleSplit(n_splits=250, test_size=.25)\n",
    "fullModel = make_pipeline(StandardScaler(), Ridge(alpha=10))\n",
    "CVInfo = cross_validate(fullModel,Xs,y, cv=shuffle,return_train_score=True,n_jobs=-1)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 2\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', Ridge(alpha=10))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6421843540753434\n",
      "0.3473696952879355\n"
     ]
    }
   ],
   "source": [
    "shuffle = ShuffleSplit(n_splits=250, test_size=.25)\n",
    "CVInfo = cross_validate(pipe,Xs,y, cv=shuffle,return_train_score=True,n_jobs=-1)\n",
    "print(np.mean(CVInfo['train_score']))\n",
    "print(np.mean(CVInfo['test_score']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are very similar with the last run that set up with ridge with a single StandardScaler() on the full sample. This model is not doing anything differently because make_pipeline preprocesses with standard scaling and then ridge regression and it is doing the same set up as the last run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. GridSearch\n",
    "\n",
    "Set up a formal scikit learn GridSearch for the best hyperparameter, alpha in the Ridge regression.\n",
    "\n",
    "Build a pipeline model with the standard scaler.  Set up a search across the following list of alpha values,\n",
    "[0.1, 0.25, 0.5, 1., 2., 5., 10.,25.,50.,100.,150.,200.]\n",
    "\n",
    "Run the search using the same shuffle_split parameters that you have used, and the (Xs,y) pair.\n",
    "\n",
    "Print a nice table of the (rank_test_score, mean_test_score, param_ridge_alpha).\n",
    "\n",
    "Print the best_params.\n",
    "\n",
    "Get the best model and perform your usual cross-validation on the (Xs,y) pair.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rank_test_score  mean_test_score param_ridge__alpha\n",
      "0                12         0.307054                0.1\n",
      "1                11         0.307346               0.25\n",
      "2                10         0.307830                0.5\n",
      "3                 9         0.308787                1.0\n",
      "4                 8         0.310659                2.0\n",
      "5                 7         0.315960                5.0\n",
      "6                 6         0.323839               10.0\n",
      "7                 5         0.341779               25.0\n",
      "8                 3         0.358989               50.0\n",
      "9                 1         0.369341              100.0\n",
      "10                2         0.365649              150.0\n",
      "11                4         0.356366              200.0\n"
     ]
    }
   ],
   "source": [
    "fullModel = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\", Ridge())\n",
    "])\n",
    "\n",
    "param_grid={'ridge__alpha':[0.1, 0.25, 0.5, 1., 2., 5., 10.,25.,50.,100.,150.,200.]}\n",
    "\n",
    "shuffle_split = ShuffleSplit(test_size=0.25, n_splits=250)\n",
    "# set up search\n",
    "grid_search=GridSearchCV(fullModel,param_grid,cv=shuffle_split,\n",
    "                              return_train_score=True,n_jobs=-1)\n",
    "\n",
    "grid_search.fit(Xs,y)\n",
    "# move results into DataFrame\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "print(results[['rank_test_score','mean_test_score','param_ridge__alpha']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param: {'ridge__alpha': 100.0}\n",
      "best model: Pipeline(steps=[('scaler', StandardScaler()), ('ridge', Ridge(alpha=100.0))])\n",
      "best test score: 0.36934067070109017\n",
      "(Xs, y) pair\n",
      "Mean Train Score: 0.6007680021654694\n",
      "Mean Test Score: 0.3694136575099341\n"
     ]
    }
   ],
   "source": [
    "# Print best params and model\n",
    "print(\"best param:\",grid_search.best_params_)\n",
    "print(\"best model:\",grid_search.best_estimator_)\n",
    "print(\"best test score:\",grid_search.best_score_)\n",
    "\n",
    "# This is best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Rerun cross validation for best model \n",
    "CVInfo = cross_validate(best_model, Xs, y, cv=shuffle,return_train_score=True)\n",
    "\n",
    "print(\"(Xs, y) pair\")\n",
    "print(\"Mean Train Score:\", np.mean(CVInfo['train_score']))\n",
    "print(\"Mean Test Score:\", np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Grid search with formal train/validation/test split\n",
    "\n",
    "Repeat your previous grid search, but this time follow the Ames real estate example by first splitting your data into a train_val part, and a test part.  Perform the grid search on the train_val part.  Report the best test set score from the grid_search (this is the mean of the monte-carlo cross validations).  Then take the best model.  Fit it to the entire train_val sample, and then report the score for the train_val sample, and also the test sample created at the start.\n",
    "\n",
    "Compare performance between the final test sample, and the grid_search test.  Do you have any possible explation for the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param: {'ridge__alpha': 100.0}\n",
      "best model: Pipeline(steps=[('scaler', StandardScaler()), ('ridge', Ridge(alpha=100.0))])\n",
      "best test score: 0.32357813270993185\n",
      "Mean Train Score: 0.6157125708044423\n",
      "Mean Test Score: 0.31739021818840896\n"
     ]
    }
   ],
   "source": [
    "X_trainValid, X_test, y_trainValid, y_test = train_test_split(Xs,y,test_size=0.25)\n",
    "# implement search (again use trainValid data)\n",
    "grid_search.fit(X_trainValid,y_trainValid)\n",
    "# Print best params and model\n",
    "print(\"best param:\",grid_search.best_params_)\n",
    "print(\"best model:\",grid_search.best_estimator_)\n",
    "print(\"best test score:\",grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Rerun cross validation for this model just to check\n",
    "CVInfo = cross_validate(best_model, X_trainValid, y_trainValid, cv=shuffle,return_train_score=True,n_jobs=-1)\n",
    "\n",
    "print(\"Mean Train Score:\",np.mean(CVInfo['train_score']))\n",
    "print(\"Mean Test Score:\",np.mean(CVInfo['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test sample:\n",
      "0.39274631861202913\n"
     ]
    }
   ],
   "source": [
    "# Try it on the final test sample\n",
    "# You can now retrain on the full testValid sample\n",
    "print(\"Final test sample:\")\n",
    "best_model.fit(X_trainValid,y_trainValid)\n",
    "print(best_model.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean test score for the best model on the final test sample is sightly higher than that of the grid_search test. I think it might be because when I did the train_val/test split, the sets might not have the same underlying distribution which could result in the test score from the final test sample to be slightly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
